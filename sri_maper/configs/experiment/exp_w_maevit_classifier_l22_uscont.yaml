# @package _global_

defaults:
  - override /preprocess: tungsten-skarn-natl.yaml
  - override /model: maevit_classifier.yaml
  - override /trainer: ddp
  - override /callbacks: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# tags: ["W", "ViT", "cont-US", "l22", "not-pretrained"]
tags: ["W", "ViT", "cont-US", "l22", "pretrained"]
task_name: "cmta3-classifier-W"

seed: 1234
extract_attributions: false

data:
  window_size: 5
  tif_dir: ${paths.data_dir}/H3_dilation_5/Tungsten-Skarn
  likely_neg_range: [0.25,0.75]
  frac_train_split: 0.5

model:
  optimizer:
    _target_: torch.optim.AdamW
    lr: 1e-3
    weight_decay: 1e-2
  net:
    _target_: sri_maper.src.models.mae_vit_classifier.CLSClassifer
    backbone_ckpt: "logs/cmta3-pretrain-maevit/runs/2024-03-29_15-37-39/checkpoints/ssim_0.915-v1.ckpt"
    backbone_net:
      _target_: sri_maper.src.models.mae_vit.MAE_ViT
      image_size: ${data.window_size}
      patch_size: 1
      input_dim: 77
      enc_dim: 256
      encoder_layer: 6
      encoder_head: 8
      dec_dim: 128
      output_dim: ${model.net.backbone_net.input_dim}
      decoder_layer: 2
      decoder_head: 4
      mask_ratio: 0.0
    freeze_backbone: true
    # freeze_backbone: false
    dropout_rate: 0.5
  compile: false
  gain: 1.0
  mc_samples: 100
  smoothing: 0.2
  extract_attributions: ${extract_attributions}

trainer:
  min_epochs: 100
  max_epochs: 100
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  val_check_interval: 0.5
  # gradient_clip_val: 1.0

logger:
  wandb:
    # name: "ViT|not-pretrained|not_frozen|do_ll|lr=${model.optimizer.lr}"
    # name: "ViT|pretrained|not_frozen|do_ll|"
    # name: "ViT|pretrained|frozen|do_ll|l22|uscont|lr=${model.optimizer.lr}"
    name: "ViT|pretrained|frozen|do_ll_bn_prelu_do_ll_bn_prelu_do_ll|lr=${model.optimizer.lr}"

callbacks:
  model_checkpoint:
    monitor: val/auprc
  early_stopping:
    monitor: val/auprc_best
